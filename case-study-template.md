# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: Программа не должна потреблять больше 70Мб памяти при обработке файла data_large.txt в течение всей своей работы.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за время около 10мин, за исключением переписывания логики метода на работу в потоковом стиле.

Вот как я построил `feedback_loop`:
Создал бенчмарк и ruby файлы под каждый вид профилирования. Как аргумент передаю количество строк.
Вот как я построил `feedback_loop`:
- Запускаю бенчмарк.
- Запускаю профилировщик.
- Определяю главную точку роста.
- Вношу изменения.
- Проверяю гипотезу повторным запуском профилировщика.
- Защищаю изменения тестом.

Для первоначальной оценки запустил бенчмарк на 50_000 строк:
{"3.3.6":{"gc":"enabled","time":14.96,"gc_count":357,"memory":"269 MB"}}

Запустил в отдельном треде репорт потребления памяти в динамике:
* [2025-02-12 22:53:50 +0400] Memory usage: 22.00 MB
* [2025-02-12 22:53:52 +0400] Memory usage: 178.00 MB
* [2025-02-12 22:53:54 +0400] Memory usage: 194.00 MB
* [2025-02-12 22:53:56 +0400] Memory usage: 210.00 MB
* [2025-02-12 22:53:57 +0400] Memory usage: 229.00 MB
* [2025-02-12 22:53:59 +0400] Memory usage: 255.00 MB
* [2025-02-12 22:54:01 +0400] Memory usage: 281.00 MB
* [2025-02-12 22:54:03 +0400] Memory usage: 304.00 MB
* [2025-02-12 22:54:05 +0400] Memory usage: 334.00 MB

Решаю начать поиск точек роста с memory_profiler

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался memory_profiler

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- memory_profiler показал главную точку роста в строке 7.16 GB rails-optimization-task2/task-2.rb:55
- Проблема конкатенации уже знакома по прошлому заданию, решаю ее заменой метода + на <<
То же самое проделываю и с предыдущей строкой.
- Метрика уменьшилась на 54 Мб на 50_000 срок
{"3.3.6":{"gc":"enabled","time":14.16,"gc_count":128,"memory":"215 MB"}}
Кратно уменьшилось количество срабатываний gc
- Найденная точка роста перестала ей быть и уже не попадает в отчет

### Ваша находка №2
- memory_profiler показал главную точку роста в строке
2.60 GB  /Users/alex/pets/rails-optimization-task2/task-2.rb:104
также обратил внимание на большое количество алоцированные пробелов
223085  " "

    169220  /rails-optimization-task2/task-2.rb:143
     53865  /rails-optimization-task2/task-2.rb:40
- Вынес select из итератора, сгруппировав сессии по user_id
  Исправил конкатенацию пробела, она там не нужна("#{user.attributes['first_name']}" + ' ' + "#{user.attributes['last_name']}").

  Избавился от Date.parse, он также не нужен.

  Добавил # frozen_string_literal: true
- Количество потребляемой памяти уменьшилось на 160MB на 50_000 строк
{"3.3.6":{"gc":"enabled","time":0.27,"gc_count":30,"memory":"53 MB"}}
- Найденные точки роста престали ими быть

Смотрю метрики на 400_000 строк:

{"3.3.6":{"gc":"enabled","time":2.48,"gc_count":51,"memory":"412 MB"}}

### Ваша находка №3
- Использую stackprof для поиска очередной точки роста:

   (5876907  (57.5%)     5876907  (57.5%)     String#split)

  Главная точка роста split методы в work и parse_session иетодах
  Зная что далее всеравно предстоит переписывать код в потоковом стиле, решаю не тратить время на
  оптимизацию split метода, потому как далее эта логика поменяется.
- Переписал код в потоковом стиле. Использовал гем Oj

Так как порядок не важен, сначала запишем usersStats (как объект, куда по мере обработки добавим пары "имя юзера" => stats), а затем добавим остальные ключи.

- После внедрения новой логики получил метрику на data_large.txt файле в 1MB и выполнил бюджет

  {"3.3.6":{"gc":"enabled","time":3.78,"gc_count":3037,"memory":"1 MB"}}
- 2738453(51.0%) 2738453(51.0%) String#split - остался главной точкой роста


### Ваша находка №4
- Отчет ruby-prof qcachegring показал главную точку роста в String#split(36%)
- Изучил возможности профилирования в ruby-prof qcachegring, но т.к. бюджет в 1MB
меня вполне устравивает, решл завершить оптимизацию.
- Защитил изменетестом, который проверяет потребление памяти на большом файле(менее 70 Mb).

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с оценки в 1.5Gb до 1Mb для большого файла и уложиться в заданный бюджет.

Наиболее полезным и удобным показалось профилирование потребления памяти с помощью memory_profiler и ruby-prof.

Гигантскую долю памяти удалось сэкономить преписав программу в потоковом стиле с помощью гема Oj.

Кажется для более точной оценки потребления памяти необходимо учитывать память которая была выделена
до начала выполнения профилируемого метода(~20Mb) и вычитать это значение от потребления памяти которое зафмксировали по заверешению работы метода.

## Защита от регрессии производительности
Защитил изменетестом, который проверяет потребление памяти на большом файле(менее 70 Mb).
