# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решила исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумала использовать такую метрику: количество потребляемой программой памяти, бюджет на метрику - 70Мб.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроила эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений менее чем за минуту.

Вот как я построил `feedback_loop`:
- Запускаю профилировщик при выполнении программы
- Анализирую и выделяю главную точку роста
- Вношу изменения в программу
- Вычисляю новое значение метрики, смотрю, изменилось ли количество потребляемой памяти в меньшую сторону
- Если да, запускаю еще раз профилировщик, проверяю, что главная точка роста изменилась
- Сохраняю изменения и делаю коммит

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовалась профилировщиками `ruby-prof`, `stackprof`, гемом `memory-profiler`, инструментом `valgrind massif visualizer`.

Так как программа изначально считывала в память и записывала в переменные большой объем данных, первым шагом я переписала ее в потоковом стиле. Я начала считывать входной файл по строкам, а писать JSON при помощи гема `Oj`. Для подсчета уникальных юзеров и сессий я ввела две отдельные переменные, которые инкрементировала по ходу обработки входного файла, а для вывода уникальных браузеров добавила структуру `Set`. Сессии обрабатываемого в данный момент юзера я добавляла в переменную `current_sessions`, которую передавала далее в метод `write_stats_for` для вычисления и тут же записи статистики по юзеру. После того, как я переписала программу в потоковом стиле, я начала искать точки роста при помощи профилировщиков.

Вот какие проблемы удалось найти и решить

### Date.parse()
- `memory-profiler` показывает строку
  ```ruby
  writer.push_value(sessions.map{|s| s['date']}.map {|d| Date.parse(d)}.sort.reverse.map { |d| d.iso8601 })
  ```
- Выделила `sessions.map{|s| s['date']}` в отдельную переменную, к которой применяла bang-методы, переписала парсинг даты:
  ```ruby
  dates = sessions.map{|s| s['date']}
  writer.push_key('dates')
  writer.push_value(dates
                    .sort!
                    .reverse!
                    .map! do |d|
                      ary = d.split('-')
                      Date.new(ary[0].to_i, ary[1].to_i, ary[2].to_i).iso8601
                    end)
  ```
- Потребление памяти снизилось с 22Мб до 20Мб
- `memory-profiler` перестал показывать эту строку, как аллоцирующую максимальный объем памяти

### Ваша находка №2
- какой отчёт показал главную точку роста
- как вы решили её оптимизировать
- как изменилась метрика
- как изменился отчёт профилировщика

### Ваша находка №X
- какой отчёт показал главную точку роста
- как вы решили её оптимизировать
- как изменилась метрика
- как изменился отчёт профилировщика

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *того, что у вас было в начале, до того, что получилось в конце* и уложиться в заданный бюджет.

*Какими ещё результами можете поделиться*

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы *о performance-тестах, которые вы написали*
