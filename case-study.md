# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику:
1) отчет профилировщика должен поменять главную точку роста
2) обработка файла должна ускориться

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 10-15 секунд

Вот как я построил `feedback_loop`:
1) взять кол-во данных, время обработки которых не превышает 5 секунд
2) построить отчет профилировщика и найти главную точку роста
3) оптимизировать эту точку
4) запустить тесты 
5) проверить отчет профилировщика
6) проверить временные показатели

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался memory_profiler, ruby-prof, stackprof

Вот какие проблемы удалось найти и решить

Для тренировки прошлась по исходному файлу и нашла места, где можно оптимизировать память
Написала ранер, в котором запускается программа и второй поток, который мониторит память и выводит ее в консоль 1 раз в секунду

Показатели до оптимизации 20_000:
```
INITIAL MEMORY USAGE: 19 MB
MEMORY USAGE: 20 MB
MEMORY USAGE: 199 MB
MEMORY USAGE: 232 MB
```

### Ваша находка №1
1) Объем данных: 20_000, время: 2.859999
2) Профилировщик: memory_profiler
3) Главная точка роста: ```sessions = sessions + [parse_session(line)] if cols[0] == 'session'```: 1.15 GB из 1.70 GB за всю работу
```
allocated memory by class
-----------------------------------
   1.65 GB  Array
```
4) ```sessions = sessions + [parse_session(line)]``` -> ```sessions << parse_session(line)```
5) Метрики профайлера:
```
allocated memory by file: 551.33 MB
Оптимизированная строка: 800.00 kB
```
6) Главная точка роста поменялась
7) Время обработки: 2.815428

### Ваша находка №2
1) Объем данных: 20_000, время: 2.815428
2) Профилировщик: stackprof
3) Главная точка роста: String#split, 32.7%. Из них 40.4% в parse_session
4) Уберем двойное разбиение строки и передадим в метод уже готовый массив
5) Метрики профайлера: String#split уменьшился до 22.9%, кол-во аллокаций 293909 -> 175231, общее кол-во аллокаций: 900013 -> 764381
6) Главная точка роста частично поменялась (все еще String#split, но уже в другом методе)
7) Время обработки: 2.759818

### Ваша находка №3
1) Объем данных: 20_000, время: 2.754138
2) Профилировщик: ruby-prof
3) Главная точка роста по аллокациям:
```
Allocations: 61.14% (61.14%) Object#collect_stats_from_users -> 24.40% (73.45%) <Class::Date>#parse -> 4.44% Regexp#match
Memory: 65.74% (65.74%) Object#collect_stats_from_users -> 22.94% (70.95%) <Class::Date>#parse -> 5.26% Regexp#match
```
4) Так как дата приходит в уже правильном формате, то просто уберем парсинг даты
5) Главная точка роста поменялась
6) Время обработки: 2.712649

Показатели после оптимизации для 20_000:
```
INITIAL MEMORY USAGE: 22 MB
MEMORY USAGE: 23 MB
MEMORY USAGE: 80 MB
MEMORY USAGE: 116 MB
FINAL MEMORY USAGE: 116 MB
```

### На этом закончим оптимизацию полного файла, перепишем на потоковую обработку

После перевода программы на потоковый подход потребление памяти на большом файле не превышает 20Мб и время сократилось до ~6-7 секунд
```
INITIAL MEMORY USAGE: 18 MB
MEMORY USAGE: 18 MB
MEMORY USAGE: 19 MB
MEMORY USAGE: 19 MB
MEMORY USAGE: 19 MB
MEMORY USAGE: 19 MB
MEMORY USAGE: 19 MB
MEMORY USAGE: 19 MB
FINAL MEMORY USAGE: 19 MB
```

## Продолжим вникать в детали системы, чтобы найти главные точки роста

### Ваша находка №1
1) отчет memory_profiler:
основная точка роста ```12.05 MB: type, *info = line.strip.split(LINE_SEPARATOR)```
2) оптимизация: заменим strip на strip!
3) ```10.45 MB: type, *info = line.strip!.split(LINE_SEPARATOR)```
4) метрика изменилась, но главная точка роста все еще та же

### Ваша находка №2
1) отчет memory_profiler:
   основная точка роста ```10.45 MB: type, *info = line.strip.split(LINE_SEPARATOR)```
2) заметим, что строка session аллоцируется 16_954 из 20_000 - на каждой строке
3) попробовала разные вариации - от удаления префикса строки с дальнейшим разбиением до прсто сплита по подстроке. Удаление префикса позволяет избавиться от лишних аллокаций, но прибавляет потребления памяти в процессе, и код теряет свою читаемость. Остальные варианты просто снижают читаемость кода и добавляют потребляемой памяти
4) поэтому решила что на текущем этапе при потреблении 19МБ за любое кол-во строк при 18МБ на старте - это оптимальное решение и дальше оптимизировать смысла нет

### Ваша находка №3
1) также из отчета видно, что аллоцируются новые строки-ключи при записи в отчет на каждого юзера, потому что идет преобразование из symbol в string

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с 232 MB для 20_000 строк до 19 MB для любого кол-ва данных и уложиться в заданный бюджет.

Но, если взять граничное значение в виде один юзер и все сессии (кол-во сессий как в файле large), то память конечно раздувается, вероятно из-за того что происходит накопление не уникальных браузеров / дат, и из-за этого время ухудшается до ~8 секунд
```
INITIAL MEMORY USAGE: 18 MB
MEMORY USAGE: 18 MB
MEMORY USAGE: 137 MB
MEMORY USAGE: 242 MB
MEMORY USAGE: 336 MB
MEMORY USAGE: 410 MB
MEMORY USAGE: 661 MB
FINAL MEMORY USAGE: 695 MB
```

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы я написала перфоманс тест на время и аллокацию памяти.
Правда в данном случае нас больше интересует чтобы программа не потребляла больше Х памяти в течение всего выполнения, а тест проверяет общее кол-во аллоцированной памяти, что не совсем подходит для текущей задачи.
