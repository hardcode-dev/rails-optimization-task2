# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику:
После того как я попробовал все описание в уроке библиотеки, я отановыился на использовании `memory-profiler` как основного профилировщика и метрики, а также `Название этой херни из докера`

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за неделю с перерывами (чистое время - два дня)

Вот как я построил `feedback_loop`:
1. с помощью memory profiler определяем слабую строчку кода
2. с помощью ruby-prof#graph детально рассмартриваем кто ее вызывает и кого вызывает она из потребителей памяти
3. Оптимизируем
4. запускаем тест чтобы проверить что все работает также
5. Проверяем результат с помощью memory profiler (на файле в 10.000 строк)

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался memory profiler. Он очень хорошо показывает распределение памяти как по строчкам, так и по классам. Также я пользовался `Название этой херни из докера` чтобы понять как память распределяется по времени работы программы

Вот какие проблемы удалось найти и решить

### Ваша находка №1
- какой отчёт показал главную точку роста
  `memory-profiler`, `ruby-prof#graph`
  Я включил первые три шага в один, потому что они были очевидны и без профилировщиков
  Первый шаг я сделал просто для того как такие очевидные вещи повлияют на расход памяти
- как вы решили её оптимизировать 
  1. Заменил `Array + [value]` на `Array << value`
  2. убрал Date parsing
  3. добавил константы на пробел и запятую и сделал их Frozen Strings
- как изменилась метрика
  `memory profiler` до начала и после каждого шага
  767.19 MB -> 245.15 MB -> 217.35 MB -> 215.72 MB
  от `Название этой херни из докера` скриншот не сохранил, но график был как на лекции, потребление росло со временем
- как изменился отчёт профилировщика
  Array продолжал оставаться главным потребителем памяти

### Ваша находка №2
- какой отчёт показал главную точку роста
  `memory-profiler`, ruby-prof#graph
- как вы решили её оптимизировать
  Даже в Readme сказано что нужно перестроить алгоритм так чтобы не хранить данные в памяти, а записывать их сразу по получении
  Так я и поступил
- как изменилась метрика
  `memory-profiler` -> 38.68 MB 
  `Название этой херни из докера`
  ![after step 2 picture](/optimization_tools/After_step_2.png)
- как изменился отчёт профилировщика
  Кардинально

### Ваша находка №3
- какой отчёт показал главную точку роста
  `memory-profiler`, ruby-prof#graph
  Главным потребителем памяти были части кода где я записывал данные в файл результата
- как вы решили её оптимизировать
  подсмотрел что другие используют `Oj::StreamWriter`, решил его попробовать
- как изменилась метрика
  `memory-profiler` -> 35.26 MB 
  `Название этой херни из докера`
  ![after step 3 picture](/optimization_tools/After_step_3.png)
  На этом шаге `memory-profiler` и `Название этой херни из докера` стали выдавать разные результаты.
  Если бы вы объяснили почему, я был бы благодарен.
  Я предполагаю что `memory-profiler` смотрит только на мой процесс, а `Название этой херни из докера` на весь rvm
  а rvm после 40Mb память в систему не отдает
- как изменился отчёт профилировщика
  Я ждал большего конечно, но `User.serialize` опустился с первого местя в середину списка
  
### Ваша находка №4
- какой отчёт показал главную точку роста
  `memory-profiler`, ruby-prof#graph
  Array.uniq и Array.map
- как вы решили её оптимизировать
  решил попробовать SortedSet упомянутый в замечаниях к предыдущему заданию
  также заменил `map(&:upcase).join(', ')` на `reduce`
- как изменилась метрика
  `memory-profiler` -> 30.55 MB
  `Название этой херни из докера`
  ![after step 4 picture](/optimization_tools/After_step_4.png)
- как изменился отчёт профилировщика
  теперь `set` gem стал потреблять больше половины памяти =)

### Ваша находка №5
- какой отчёт показал главную точку роста
  `memory-profiler` показал что главные потребители памяти это:
  `gem set`
  строка `cols = line.split(COMMA)`
  строка `user_browsers = @browsers.reduce(''){|sum, b| sum.empty? ? b.upcase : "#{sum}#{COMMA} #{b.upcase}"}`
  Хотел уже было закругляться с оптимизацией, но прокрутил отчет чуть дальше и заметил что программа создает газилион строчек `session` и `user`
- как вы решили её оптимизировать
  Решил что все строчки которые используются более одного раза должны быть замороженными константами
  кроме `session` и `user` это были все ключи юзера в отчете и пустая строка ''
- как изменилась метрика
  `memory-profiler` -> 27.28 MB
  ![memory-profiler final](/optimization_tools/memory_profiler_final.png)
  `Название этой херни из докера`
  ![after step 4 picture](/optimization_tools/After_step_5.png)
  `Название этой херни из докера` на 100.000 строках
  ![after step 4 picture](/optimization_tools/After_step_5_big_file.png)
  `Название этой херни из докера` на 100.000 строках и руби 3
  ![after step 4 picture](/optimization_tools/After_step_5_big_file_ruby_3.png)
- как изменился отчёт профилировщика
  Не особо он изменился

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с 767.19 MB 27.28 MB и уложиться в заданный бюджет.

Время работы сильно больше по сравнению с первым заданием. В реальной жизни я наверное сделал бы что нибудь среднее, читал/писал бы пачками такого объема на который не жалко памяти

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы написал два теста чтобы убедится что сложность по памяти линейная
