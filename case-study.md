# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумала использовать такую метрику:

Измерила (вариант с изменениями из первого задания) с помощью предложенной команды:

`puts "MEMORY USAGE: %d MB" % (`ps -o rss= -p #{Process.pid}`.to_i / 1024)`

Результат в начале:

```
# с GC

MEMORY USAGE: 2444 MB

# без GC

MEMORY USAGE: 5924 MB
```

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроила эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за 35 секунд.

Вот как я построила `feedback_loop`:

Прописала, чтобы оценивать кол-во памяти:
```ruby
puts "MEMORY USAGE: %d MB" % (`ps -o rss= -p #{Process.pid}`.to_i / 1024)
```

На этапе отладки потокового варианта использовала sample, к-й позволял оценить работоспособность в пределах пары секунд.

Далее подобрала sample, с к-м фидбек можно было получить за 5-20 секунд.

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовалась `ruby-prof`. Пробовала другие (stackprof, kcachgrind (да, у меня он с k)), ничего особо нового из них не узнала.

Вот какие проблемы удалось найти и решить

### Ваша находка №0

Переход на потоковую обработку.

По времени программа стала работать медленнее (25с => 33-34c , с gc)

По памяти произошло улучшение:

`MEMORY USAGE: 2444 MB`
=>
`MEMORY USAGE: 332 MB`

Думала использовать `gem 'json-write-stream'` , но неудобно писать вложенный json для `usersStats`, поэтому решила напрямую

### Ваша находка №1

memory profiler показал ,что File очень много ест памяти, но непонятно, как от него избавиться.

Также посмотрела qcachegrind (у меня kcachegrind) - много отнимают `write_user_to_json` , `Array#each`.

Также создала второй тред, вот его отчёт:

```
MEMORY USAGE: 29 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
22.006778048
```

Подумала, раз `File`, то не открывать/закрывать его для каждого юзера, а открыть на запись 1 раз.

Переписала - по памяти ничего не поменялось, но программа стала быстрее отрабатывать (27 => 21 секунд, если проверять на большом файле без профилирования)

### Ваша находка №2

Далее снова посмотрела с помощью memory_profiler:

Увидела, что String ест много памяти, причём на месте `split(',')`

Заметила, что при проверке строки "юзер" или "сессия" вообще необязательно split делать. Но также заметила, что split делается 2 раза для каждой строки: для проверки user / session и для парсинга юзера/сессии.

Сначала переписала на разовый `split` и передачу `cols` в `parse_session` и `parse_user`.

```ruby
cols = line.split(',')
...
parse_user(cols)
```

Использование памяти на sample снизилось с:
```
Total allocated: 179.51 MB (2546193 objects)
```
До:

```
Total allocated: 131.29 MB (1761624 objects)
```

### Предупреждение об особенностях работы

[Тут было ещё несколько находок и итераций, но где-то закралась ошибка, поэтому убрала их]
[+ в целом было несколько заходов туда-сюда, оставила лучший из вариантов]

### Ваша находка номер 4

Теперь (кроме File):

```ruby
current_user = User.new(attributes: parsed_user, sessions: [])
```

Можно оптимизировать `User` => `OptimizedUser`
+ увидела, что не используются id и age, их убираем из объекта.

Заменила на оптимизированного юзера без лишних полей: 
```ruby
OptimizedUser = Struct.new(:full_name, :sessions, keyword_init: true)

current_user = OptimizedUser.new(full_name: "#{first_name} #{last_name}", sessions: [])
```

Стало:

```
Total allocated: 126.35 MB (1730762 objects)
```

### Находка 5

Увидела, что у меня browser.upcase 2 раза, решила сделать 1.

```
Total allocated: 122.13 MB (1646193 objects)
```

### 6

Сделала сессию массивом.

```
Total allocated: 112.82 MB (1646193 objects)
```

+ upcase

```
Total allocated: 104.38 MB (1477055 objects)
```

### 7

Сделала один split:

```
Total allocated: 97.00 MB (1292486 objects)
```
### 8

Увидела много объектов `','`, завела константу `DELIMITER = ','` (omg, чем я занимаюсь)

```
Total allocated: 92.38 MB (1177056 objects)
# и ещё одну
Total allocated: 91.76 MB (1161626 objects)
```

### 9

Сделала `user_or_session.shift` для получения первого эл-та массива:
Ну такое:

```
Total allocated: 91.15 MB (1155726 objects)
```

### 10

Убрала `Struct`, сделала обычный класс

```
Total allocated: 88.68 MB (1140295 objects)s
```

### 11

Убрала объект `User` - тут не особо что-то изменилось.

```
Total allocated: 88.32 MB (1124864 objects)
```

### 12

Поменяла режим записи в файл:

```
Total allocated: 87.90 MB (1124625 objects)
```

### Тупик

Далее тупик, остальные ухищрения делают только хуже.

При этом, при замере на большом файле использование памяти практически не изменилось (после замены на потоковую обработку):

```
MEMORY USAGE: 27 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
10.641142708
```

Проблемные места:

```ruby
line = line.split(DELIMITER)

dates.sort.reverse

File.readlines
```

Много строк "session" создаётся при `split` + много строк типа "0", "1" и т.д.

Посмотрела stackprof, примерно то же показывает.

## 12

Попробовала переписать ещё более потоково - не накапливать сессии в рамках каждого юзера в массиве, а  считать по мере прохождения по строкам в переменных и писать сразу по позможности, юзера писать сразу.

Результат минимальный (на 100_000 строк):
```
Total allocated: 86.70 MB (1099665 objects)
```

Замеры (память и время):

На файле `data_large.txt`:

```
MEMORY USAGE: 27 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
MEMORY USAGE: 334 MB
9.926471411
```

На 100_000 строк:
```
MEMORY USAGE: 27 MB
0.243047239
```

На 300_000 строк:
```
MEMORY USAGE: 27 MB
MEMORY USAGE: 122 MB
MEMORY USAGE: 122 MB
MEMORY USAGE: 122 MB
3.195018119
```

Далее можно использовать `oj` , но т.к. он не касается проблемных мест, то не стала использовать.

## Находка 13

Решила дополнительно поресёрчить, можно ли более оптимально прочитать файл.
Просто я была уверена, что `readlines` это и есть `foreach`. Да и `open` , к-й был, сработал бы.

Заменила `readlines` на `foreach`:

Результат на data_large.txt:

```
MEMORY USAGE: 27 MB
MEMORY USAGE: 29 MB
MEMORY USAGE: 29 MB
MEMORY USAGE: 29 MB
MEMORY USAGE: 29 MB
MEMORY USAGE: 29 MB
MEMORY USAGE: 29 MB
Time: 6.599629822 seconds
TOTAL MEMORY USAGE: 29 MB
```

## Результаты
В результате проделанной оптимизации удалось обработать файл с данными.
Удалось улучшить метрику системы с использования 2444 MB и 30с до обработки целевого файла за 6-7 секунд и 29mb памяти, но не удалось уложиться в заданный бюджет.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы написана парочка performance-тестов.
