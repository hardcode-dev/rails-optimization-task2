# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: Потребление памяти.

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за за 10-20 секунд.

Вот как я построил `feedback_loop`: Создавал файл с N строк, чтобы программа могла выполнятся 10-20 секунд.

## Вникаем в детали системы, чтобы найти главные точки роста
Для того, чтобы найти "точки роста" для оптимизации я воспользовался memory_profiler, в котором смотрел какой код создает больше всего объектов, stackprof для большей детальности. Так же дополнительно был написан скрипт запускающий код в 2 потока, один из которых раз в секунду печатал потребление памяти.

Вот какие проблемы удалось найти и решить

### Ваша находка №1
Для первого профилирования я сделал файл из 10000 строк, получил потребление памяти 460 МВ, для 30000 - 405 МВ, для 50000 - 492 МВ, на этом количестве остановился.
Попробовал использовать memory_profiler, который показал 560712 созданных объектов в строке
  ```
    { 'dates' => user.sessions.map{|s| s['date']}.map {|d| Date.parse(d)}.sort.reverse.map { |d| d.iso8601 } }
  ```
Использовал stackprof, он показал `734611  (31.3%) String#split` и `380763 (16.2%) Date.parse`.
Посмотрел детальнее метод String#split, большая часть создается в методе `296135 (40.3%) Object#parse_session`
Делаю вывод что Главная точка роста - Date.parse

https://github.com/fastruby/fast-ruby?tab=readme-ov-file#date рекомендуют использовать Date.iso8601.
Потребление памяти не сильно изменилось, осталось 504 MB, `211530 (9.7%) Date.iso8601`
Попробовал Date.strftime, потребление памяти снизилось до `MEMORY USAGE: 356 MB`, `126921 (6.3%) Date.strptime`, оставил это решение.

### Ваша находка №2
Теперь результат memory_profiler стал показывать что в строке 
```
cols = line.split(',')
```
создается 392305 объектов. StackProf так же показывает что split создает много объектов, не только в этом месте
```
String#split (<cfunc>:1)
  samples:  734611 self (36.6%)  /   734611 total (36.6%)
  callers:
    392306  (   53.4%)  Object#work
    296135  (   40.3%)  Object#parse_session
    46170  (    6.3%)  Object#parse_user
```
Изучив код, принял решение отказаться от использования в данном месте метода split, а определять принадлежность к сущности user/session по началу строки. 
Общее количество объектов String#split сократилось до 392306 (24.3%), текущее место перестало был точкой роста.

### Ваша находка №3
Для понимания когда программа начинает потреблять больше памяти я написал скрипт который использует два потока, в одном выполняется программа, а другой выводит на экран каждую секунду потребляемую память. Скрипт показал что после чтения файла потребление памяти резко увеличивается. Для того чтобы всё содержимое файла не помещать в память, было решено переписать программу с использованием чтения строк.
После изменения кода, программа на больших данных стала тратить 22 МБ.

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с более 700 Мб до менее 70 Мб и уложиться в заданный бюджет.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы был создан performance тест.

